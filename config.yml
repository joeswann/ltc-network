# Dataset settings
dataset:
  text:
    type: "wikitext"
    name: "wikitext-2-raw-v1"
    split: "train"
    max_length: 128
  timeseries:
    sequence_length: 60
    period: "5y"
    interval: "1d"
    symbols:
      [
        "AAPL",
        "GOOGL",
        "MSFT",
        "AMZN",
        "META",
        "NVDA",
        "TSLA",
        "JPM",
        "JNJ",
        "V",
      ]
  toy:
    num_samples: 10000
    seq_length: 100
    num_classes: 20

# Model settings
model:
  hidden_size: 128
  num_epochs: 40
  gradient_clip: 1.0
  learning_rate: 0.001
  weight_decay: 0.0
  momentum: 0.9

# LTC specific settings
ltc:
  steps: 20
  step_size: 0.005
  solver: "RungeKutta"
  adaptive: true

# GRU and LSTM specific settings
rnn:
  num_layers: 4

# Training settings
train:
  batch_size: 64

# Prediction strategies settings
prediction_strategies:
  window_size: 60
  confidence_threshold: 0.02
  position_size: 0.1
  stop_loss: 0.05
  take_profit: 0.1

# Paths
paths:
  strategies: strategies
  models: models

# Logging
logging:
  level: INFO
  format: "%(asctime)s - %(levelname)s - %(message)s"
